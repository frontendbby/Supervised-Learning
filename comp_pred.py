# -*- coding: utf-8 -*-
"""comp_pred.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1I8ICH16pOcictBoFkVdixUOwuK7P0OP7
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm

computers_df = pd.read_csv('https://raw.githubusercontent.com/frontendbby/Fun-datasets/refs/heads/main/Computers.csv')
computers_df.head(15)

computers_df.info()

sns.histplot(computers_df)

sns.pairplot(computers_df)

computers_df.corr(numeric_only=True)

sns.heatmap(computers_df.corr(numeric_only=True), annot=True)

x = sm.add_constant(computers_df["speed"])
y = computers_df["price"]

model = sm.OLS(y, x).fit()
model.summary()

computers_df["price"]

prices = [1499, 1795, 1595, 1849, 3295, 3695, 1720, 1995, 2225, 2575]

x_predict = sm.add_constant(pd.DataFrame({"price": prices}))
x_predict

predictions = model.predict(x_predict)
predictionsname = "predictions"

(computers_df
 .query ("price in @prices")
 .groupby ("price")
 .agg(mean_price_agg=('price', 'mean'))
 .reset_index()
 .rename(columns={'price': 'actual_price'})
 .drop(columns=['mean_price_agg'])
 .merge(predictions.rename('predicted_price'), left_index =True, right_index=True)
 .assign(
     error = lambda x: x["predicted_price"] - x ["actual_price"],
     pct_difference = lambda x: (x["error"] / x ["actual_price"])*100
 )
)

numerical_features = computers_df[['ram', 'speed', 'hd', 'screen']]
categorical_features = pd.get_dummies(computers_df[['cd', 'multi', 'premium']], drop_first=True)
X_multi = pd.concat([numerical_features, categorical_features], axis=1)
print("X_multi DataFrame created successfully with shape:", X_multi.shape)
X_multi.head()

X_multi = sm.add_constant(X_multi)
y = computers_df['price']

multi_model = sm.OLS(y, X_multi).fit()
multi_model.summary()

multi_predictions = multi_model.predict(X_multi)
print("Generated predictions using multi_model:")
print(multi_predictions.head())

actual_comparison_df = computers_df[computers_df['price'].isin(prices)].reset_index(drop=True)
multi_predictions_for_comparison = multi_predictions.loc[computers_df['price'].isin(prices)].reset_index(drop=True)

comparison_df_multi = pd.DataFrame({
    'actual_price': actual_comparison_df['price'],
    'predicted_price': multi_predictions_for_comparison
})

comparison_df_multi = comparison_df_multi.assign(
    error=lambda x: x['predicted_price'] - x['actual_price'],
    pct_difference=lambda x: (x['error'] / x['actual_price']) * 100
)

print("Prediction errors and percentage differences for selected prices:")
print(comparison_df_multi)

plt.figure(figsize=(10, 6))
sns.scatterplot(x='actual_price', y='predicted_price', data=comparison_df_multi)
plt.plot([comparison_df_multi['actual_price'].min(), comparison_df_multi['actual_price'].max()],
         [comparison_df_multi['actual_price'].min(), comparison_df_multi['actual_price'].max()],
         color='red', linestyle='--', label='Perfect Prediction Line')
plt.title('Actual vs. Predicted Prices (Multi-variable Model)')
plt.xlabel('Actual Price')
plt.ylabel('Predicted Price')
plt.legend()
plt.grid(True)
plt.show()

### Definición, ajustes, cálculo de residuos

# Definición de variables
features_1 = ['speed', 'hd', 'ram', 'screen']
X1 = sm.add_constant(computers_df[features_1])
y = computers_df['price']

# Ajuste del modelo
model_1 = sm.OLS(y, X1).fit()
print(model_1.summary())

# Cálculo de residuos
residuos_1 = model_1.resid
predicciones_1 = model_1.fittedvalues

# Trazado de residuos
plt.figure(figsize=(10, 6))
sns.scatterplot(x=predicciones_1, y=residuos_1)
plt.axhline(y=0, color='red', linestyle='--')
plt.title('Gráfico de Residuos: Modelo de Hardware Base')
plt.xlabel('Valores Ajustados (Predicciones)')
plt.ylabel('Residuos')
plt.show()

# Definición de variables extendidas
features_2 = ['speed', 'hd', 'ram', 'screen', 'ads', 'trend']
X2 = sm.add_constant(computers_df[features_2])

# Ajuste del modelo
model_2 = sm.OLS(y, X2).fit()
print(model_2.summary())

# Cálculo de residuos
residuos_2 = model_2.resid
predicciones_2 = model_2.fittedvalues

# Trazado de residuos
plt.figure(figsize=(10, 6))
sns.scatterplot(x=predicciones_2, y=residuos_2)
plt.axhline(y=0, color='red', linestyle='--')
plt.title('Gráfico de Residuos: Modelo Extendido (con Ads y Trend)')
plt.xlabel('Valores Ajustados (Predicciones)')
plt.ylabel('Residuos')
plt.show()

import scipy.stats as stats

# Gráfico Q-Q para el modelo extendido
fig = sm.qqplot(model_2.resid, line='s')
plt.title('Gráfico Q-Q de Residuos (Validación de Normalidad)')
plt.show()

plt.figure(figsize=(12, 6))
sns.violinplot(x='premium', y='price', data=computers_df, hue='cd', split=True)
plt.title('Impacto de "Premium" y "CD" en la Distribución de Precios')
plt.show()

fig = plt.figure(figsize=(12, 8))
sm.graphics.plot_partregress_grid(model_2, fig=fig)
plt.show()

from statsmodels.stats.outliers_influence import variance_inflation_factor

# Cálculo del VIF
vif_data = pd.DataFrame()
vif_data["feature"] = X2.columns
vif_data["VIF"] = [variance_inflation_factor(X2.values, i) for i in range(len(X2.columns))]
print(vif_data)

import statsmodels.api as sm
import matplotlib.pyplot as plt
import numpy as np

# 1. Calculamos la influencia del modelo extendido (el que tiene 'ads' y 'trend')
influence = model_2.get_influence()

# 2. Obtenemos la Distancia de Cook y los valores de Leverage (hat values)
(c, p) = influence.cooks_distance
leverage = influence.hat_matrix_diag

# 3. Definimos un umbral crítico (Regla de oro: 4/n)
n = len(computers_df)
threshold = 4 / n

# 4. Visualización: Gráfico de Distancia de Cook
plt.figure(figsize=(12, 5))
plt.stem(np.arange(len(c)), c, markerfmt=",")
plt.axhline(y=threshold, color='r', linestyle='--', label=f'Umbral Crítico ({threshold:.4f})')
plt.title("Distancia de Cook: Identificación de Observaciones Dominantes")
plt.xlabel("Índice de la computadora")
plt.ylabel("Distancia de Cook")
plt.legend()
plt.show()

# 5. Visualización: Residuos vs Leverage (Influence Plot)
fig, ax = plt.subplots(figsize=(10, 8))
sm.graphics.influence_plot(model_2, ax=ax, criterion="cooks")
plt.title("Gráfico de Influencia: Residuos Estudiantizados vs Leverage")
plt.show()

# 6. Listado de las 5 computadoras más influyentes
print("Top 5 Observaciones que más alteran el modelo:")
influential_points = computers_df.iloc[np.argsort(c)[-5:]]
print(influential_points[['price', 'speed', 'hd', 'ram', 'screen', 'ads', 'trend']])
